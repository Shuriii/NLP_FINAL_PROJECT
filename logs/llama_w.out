Starting job...
Using device: cuda
Loading smaller model meta-llama/Meta-Llama-3-8B with fp16.
loading tokenizer
loading model
loaded model
Original number of layers: 32
Duplicating layers: [(12, 3), (18, 3)]
Original number of layers: 32
Duplicated layers: 38 total layers (original: 32)
Job done!
