{
  "accuracy": 0.642,
  "total": 500,
  "correct": 321,
  "accuracy_percent": 64.2,
  "per_subject": {
    "professional_law": {
      "accuracy": 0.5272727272727272,
      "total": 55,
      "correct": 29,
      "accuracy_percent": 52.73
    },
    "moral_scenarios": {
      "accuracy": 0.46875,
      "total": 32,
      "correct": 15,
      "accuracy_percent": 46.88
    },
    "miscellaneous": {
      "accuracy": 0.8214285714285714,
      "total": 28,
      "correct": 23,
      "accuracy_percent": 82.14
    },
    "professional_psychology": {
      "accuracy": 0.7727272727272727,
      "total": 22,
      "correct": 17,
      "accuracy_percent": 77.27
    },
    "high_school_psychology": {
      "accuracy": 0.8947368421052632,
      "total": 19,
      "correct": 17,
      "accuracy_percent": 89.47
    },
    "high_school_macroeconomics": {
      "accuracy": 0.42857142857142855,
      "total": 14,
      "correct": 6,
      "accuracy_percent": 42.86
    },
    "elementary_mathematics": {
      "accuracy": 0.38461538461538464,
      "total": 13,
      "correct": 5,
      "accuracy_percent": 38.46
    },
    "moral_disputes": {
      "accuracy": 0.6666666666666666,
      "total": 12,
      "correct": 8,
      "accuracy_percent": 66.67
    },
    "prehistory": {
      "accuracy": 0.8181818181818182,
      "total": 11,
      "correct": 9,
      "accuracy_percent": 81.82
    },
    "philosophy": {
      "accuracy": 0.8181818181818182,
      "total": 11,
      "correct": 9,
      "accuracy_percent": 81.82
    },
    "high_school_biology": {
      "accuracy": 0.7272727272727273,
      "total": 11,
      "correct": 8,
      "accuracy_percent": 72.73
    },
    "nutrition": {
      "accuracy": 0.9090909090909091,
      "total": 11,
      "correct": 10,
      "accuracy_percent": 90.91
    },
    "professional_accounting": {
      "accuracy": 0.7,
      "total": 10,
      "correct": 7,
      "accuracy_percent": 70.0
    },
    "professional_medicine": {
      "accuracy": 0.8,
      "total": 10,
      "correct": 8,
      "accuracy_percent": 80.0
    },
    "high_school_mathematics": {
      "accuracy": 0.3,
      "total": 10,
      "correct": 3,
      "accuracy_percent": 30.0
    },
    "clinical_knowledge": {
      "accuracy": 1.0,
      "total": 9,
      "correct": 9,
      "accuracy_percent": 100.0
    },
    "security_studies": {
      "accuracy": 0.6666666666666666,
      "total": 9,
      "correct": 6,
      "accuracy_percent": 66.67
    },
    "high_school_microeconomics": {
      "accuracy": 0.875,
      "total": 8,
      "correct": 7,
      "accuracy_percent": 87.5
    },
    "high_school_world_history": {
      "accuracy": 0.875,
      "total": 8,
      "correct": 7,
      "accuracy_percent": 87.5
    },
    "conceptual_physics": {
      "accuracy": 0.5,
      "total": 8,
      "correct": 4,
      "accuracy_percent": 50.0
    },
    "marketing": {
      "accuracy": 1.0,
      "total": 8,
      "correct": 8,
      "accuracy_percent": 100.0
    },
    "human_aging": {
      "accuracy": 0.5,
      "total": 8,
      "correct": 4,
      "accuracy_percent": 50.0
    },
    "high_school_statistics": {
      "accuracy": 0.625,
      "total": 8,
      "correct": 5,
      "accuracy_percent": 62.5
    },
    "high_school_us_history": {
      "accuracy": 0.0,
      "total": 7,
      "correct": 0,
      "accuracy_percent": 0.0
    },
    "high_school_chemistry": {
      "accuracy": 0.42857142857142855,
      "total": 7,
      "correct": 3,
      "accuracy_percent": 42.86
    },
    "sociology": {
      "accuracy": 0.7142857142857143,
      "total": 7,
      "correct": 5,
      "accuracy_percent": 71.43
    },
    "high_school_geography": {
      "accuracy": 1.0,
      "total": 7,
      "correct": 7,
      "accuracy_percent": 100.0
    },
    "high_school_government_and_politics": {
      "accuracy": 1.0,
      "total": 7,
      "correct": 7,
      "accuracy_percent": 100.0
    },
    "college_medicine": {
      "accuracy": 0.6666666666666666,
      "total": 6,
      "correct": 4,
      "accuracy_percent": 66.67
    },
    "world_religions": {
      "accuracy": 0.8333333333333334,
      "total": 6,
      "correct": 5,
      "accuracy_percent": 83.33
    },
    "virology": {
      "accuracy": 0.3333333333333333,
      "total": 6,
      "correct": 2,
      "accuracy_percent": 33.33
    },
    "high_school_european_history": {
      "accuracy": 0.5,
      "total": 6,
      "correct": 3,
      "accuracy_percent": 50.0
    },
    "logical_fallacies": {
      "accuracy": 1.0,
      "total": 6,
      "correct": 6,
      "accuracy_percent": 100.0
    },
    "astronomy": {
      "accuracy": 1.0,
      "total": 5,
      "correct": 5,
      "accuracy_percent": 100.0
    },
    "high_school_physics": {
      "accuracy": 0.2,
      "total": 5,
      "correct": 1,
      "accuracy_percent": 20.0
    },
    "electrical_engineering": {
      "accuracy": 0.2,
      "total": 5,
      "correct": 1,
      "accuracy_percent": 20.0
    },
    "college_biology": {
      "accuracy": 1.0,
      "total": 5,
      "correct": 5,
      "accuracy_percent": 100.0
    },
    "anatomy": {
      "accuracy": 0.8,
      "total": 5,
      "correct": 4,
      "accuracy_percent": 80.0
    },
    "human_sexuality": {
      "accuracy": 1.0,
      "total": 5,
      "correct": 5,
      "accuracy_percent": 100.0
    },
    "formal_logic": {
      "accuracy": 0.0,
      "total": 4,
      "correct": 0,
      "accuracy_percent": 0.0
    },
    "international_law": {
      "accuracy": 0.0,
      "total": 4,
      "correct": 0,
      "accuracy_percent": 0.0
    },
    "econometrics": {
      "accuracy": 0.5,
      "total": 4,
      "correct": 2,
      "accuracy_percent": 50.0
    },
    "machine_learning": {
      "accuracy": 0.5,
      "total": 4,
      "correct": 2,
      "accuracy_percent": 50.0
    },
    "public_relations": {
      "accuracy": 0.5,
      "total": 4,
      "correct": 2,
      "accuracy_percent": 50.0
    },
    "jurisprudence": {
      "accuracy": 1.0,
      "total": 4,
      "correct": 4,
      "accuracy_percent": 100.0
    },
    "management": {
      "accuracy": 0.5,
      "total": 4,
      "correct": 2,
      "accuracy_percent": 50.0
    },
    "college_physics": {
      "accuracy": 0.25,
      "total": 4,
      "correct": 1,
      "accuracy_percent": 25.0
    },
    "us_foreign_policy": {
      "accuracy": 0.75,
      "total": 4,
      "correct": 3,
      "accuracy_percent": 75.0
    },
    "global_facts": {
      "accuracy": 0.25,
      "total": 4,
      "correct": 1,
      "accuracy_percent": 25.0
    },
    "business_ethics": {
      "accuracy": 0.75,
      "total": 4,
      "correct": 3,
      "accuracy_percent": 75.0
    },
    "abstract_algebra": {
      "accuracy": 0.0,
      "total": 4,
      "correct": 0,
      "accuracy_percent": 0.0
    },
    "medical_genetics": {
      "accuracy": 0.75,
      "total": 4,
      "correct": 3,
      "accuracy_percent": 75.0
    },
    "high_school_computer_science": {
      "accuracy": 0.5,
      "total": 4,
      "correct": 2,
      "accuracy_percent": 50.0
    },
    "college_chemistry": {
      "accuracy": 0.5,
      "total": 4,
      "correct": 2,
      "accuracy_percent": 50.0
    },
    "college_computer_science": {
      "accuracy": 1.0,
      "total": 4,
      "correct": 4,
      "accuracy_percent": 100.0
    },
    "college_mathematics": {
      "accuracy": 0.0,
      "total": 3,
      "correct": 0,
      "accuracy_percent": 0.0
    },
    "computer_security": {
      "accuracy": 1.0,
      "total": 3,
      "correct": 3,
      "accuracy_percent": 100.0
    }
  },
  "per_super_category": {
    "Humanities": {
      "accuracy": 0.572289156626506,
      "total": 166,
      "correct": 95,
      "accuracy_percent": 57.23
    },
    "Other": {
      "accuracy": 0.75,
      "total": 112,
      "correct": 84,
      "accuracy_percent": 75.0
    },
    "Social_Sciences": {
      "accuracy": 0.7636363636363637,
      "total": 110,
      "correct": 84,
      "accuracy_percent": 76.36
    },
    "STEM": {
      "accuracy": 0.5178571428571429,
      "total": 112,
      "correct": 58,
      "accuracy_percent": 51.79
    }
  }
}